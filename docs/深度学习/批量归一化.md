# 批量归一化
深度学习中常常需要对输入数据进行归一化处理，即使数据没有缺失或异常值，因为归一化可以减小梯度的波动，从而加速模型的收敛过程，同时还有可避免数值溢出或某些非饱和激活函数出现分歧的潜在好处。

批量归一化就是一种用于深度神经网络训练过程中，对神经元进行归一化处理的方法。在深层网络中，因为每一层的输入数据分布可能不同，导致网络每一层学习的效果存在巨大差异，批量归一化的作用就是让每一层的输入数据在训练过程中都保持相同的分布。

我们可以这样想：模型的每个mini-batch输入都是一个样本集合，每个样本都是由高斯分布随机生成的多维数据，而每层网络中的节点都是在同一批样本下进行训练的，那么我们可以将每一层的输入数据进行归一化，达到所有输入数据满足以0为均值、1为标准差的高斯分布。通过这样的方式，训练的网络就可以更加稳定地收敛。

在深度学习中，批量归一化已经被广泛应用于卷积神经网络和全连接神经网络中，是优化深度神经网络性能的一个重要工具之一。