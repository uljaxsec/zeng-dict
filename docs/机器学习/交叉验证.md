# 交叉验证
在机器学习领域，交叉验证（Cross-Validation）是一种重要的数据分离策略。其主要目的是在有限的数据集上进行模型的训练与评估，通过交叉验证可以在一定程度上评估模型的泛化性能。

常见的数据分离策略有留出法、随机划分法和 K 折交叉验证法等。其中，留出法和随机划分法适用于数据集大、重新采样成本较低的情况，而 K 折交叉验证则是一种出色的策略，可以在数据集有限的情况下有效评估模型性能。

K 折交叉验证可以理解为将原始数据集重复地划分成 K 个子集，每个子集都做一次验证集，并将其余的 K-1 个子集作为训练集。这样一来，我们就可以得到 K 组训练/验证集，并利用它们分别训练 K 次，得到 K 次验证误差的平均值表示作为模型的性能指标。

![交叉验证示意图](https://i.loli.net/2021/08/23/8ydTtAhecbnCmLM.png)

不难看出，K 折交叉验证对于训练集样本的影响较小，但又避免了留出法中验证集较小的问题。当然，K 的选择也是一个需要考虑的问题。通常情况下，K 的值取 5 或 10。

值得一提的是，交叉验证得到的是对算法的一种无偏估计，这是重要的统计性质之一。不过，在实际应用中，还需要考虑实验的可重复性、采样的随机性、不同方法之间的比较等问题。