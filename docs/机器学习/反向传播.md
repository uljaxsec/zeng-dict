# 反向传播
在神经网络中，反向传播算法是一个重要的优化算法。它主要用于计算神经网络中每个参数对于损失函数的梯度。通过这些梯度，我们可以对每个参数进行更新来最小化损失函数。

正向传播是指从神经网络的输入开始，通过神经网络的每一层来计算输出的过程。而反向传播是通过计算造成当前损失的偏导数，将它们反向地传播回到神经网络的每一个参数。

为了更好地理解反向传播算法，让我们来看一个简单的例子。假设我们有一个神经网络，该网络有一个输入层、一个隐藏层和一个输出层。输入层有三个节点，隐藏层有两个节点，输出层有一个节点。我们的目标是训练这个神经网络，使其能够学会将输入 2 和 3 相加得到 5。

首先，我们随机初始化神经网络的参数。然后我们将输入 2 和 3 喂入神经网络中，通过正向传播，我们得到输出结果。假设这个输出结果是 4.5。那么，损失函数就是输出结果和真实结果之间的差距，即 0.5。在反向传播中，我们需要计算每个参数对损失函数的梯度。这个梯度告诉我们，如果我们将该参数稍稍调大或调小，对该参数对应的输出值以及最终的损失函数会产生什么影响。

具体而言，对于每个参数，反向传播计算出该参数对当前损失函数的偏导数。这个偏导数告诉了我们，当前的损失函数在该参数值上变化的方向，进而告诉了我们如何更新该参数，才能让损失函数减小。

最后，我们将得到的所有梯度应用于梯度下降算法中，通过不断地迭代来更新神经网络的参数，使其不断优化，直到达到我们预期的效果。

总之，反向传播算法是一种高效的神经网络优化算法。了解反向传播算法可以帮助我们更好地建立和训练深度学习模型，从而实现更好的预测性能。